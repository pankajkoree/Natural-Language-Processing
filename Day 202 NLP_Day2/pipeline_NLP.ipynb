{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE in NLP (Natural Language Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 2 :- Text Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing HTML tags\n",
    "\n",
    "sample_text = \"\"\"<!DOCTYPE html><html><body><p>This text is normal.</p><p><b>This text is bold.</b></p></body></html>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html><html><body><p>This text is normal.</p><p><b>This text is bold.</b></p></body></html>'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def striphtml(data):\n",
    "    p = re.compile('<.*?>')\n",
    "    return p.sub('', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This text is normal.This text is bold.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "striphtml(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unicode Normalization\n",
    "\n",
    "emoji_text = \"\"\"Happy birthday mitraü•πü´∂üèª janma din ko muri muri suvakamanaü•≥ dherai samjhana ra mayaü©µ ramrari padhdai janu jailey ramro marks leunuüòÇ ali barsa ko struggle ho ajhai keep working hardüñ§ ramailo garnu aaja ko¬†din¬†moj¬†gara\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Happy birthday mitraü•πü´∂üèª janma din ko muri muri suvakamanaü•≥ dherai samjhana ra maya\\U0001fa75 ramrari padhdai janu jailey ramro marks leunuüòÇ ali barsa ko struggle ho ajhai keep working hardüñ§ ramailo garnu aaja ko\\xa0din\\xa0moj\\xa0gara'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Happy birthday mitra\\xf0\\x9f\\xa5\\xb9\\xf0\\x9f\\xab\\xb6\\xf0\\x9f\\x8f\\xbb janma din ko muri muri suvakamana\\xf0\\x9f\\xa5\\xb3 dherai samjhana ra maya\\xf0\\x9f\\xa9\\xb5 ramrari padhdai janu jailey ramro marks leunu\\xf0\\x9f\\x98\\x82 ali barsa ko struggle ho ajhai keep working hard\\xf0\\x9f\\x96\\xa4 ramailo garnu aaja ko\\xc2\\xa0din\\xc2\\xa0moj\\xc2\\xa0gara'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_text.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spell checker\n",
    "incorrect_text =  \"\"\"His manner was not effusive. It seldom was; but he was glad, I\n",
    "\n",
    "think, to see me. With hardley a word spoken, but with a kindly\n",
    "\n",
    "eye, he waved me to an armchair, threw across his case of cigars,\n",
    "\n",
    "and indicated a spirit case and a gasogene in the corner. Then he\n",
    "\n",
    "stood before the fire and looked me over in his singular\n",
    "\n",
    "introspctive fashion.\n",
    "\n",
    "‚ÄúWedlock suits you,‚Äù he remarked. ‚ÄúI think, Watson, that you have\n",
    "\n",
    "put on seven and a half pounds since I saw you.‚Äù\n",
    "\n",
    "‚ÄúSeven!‚Äù I answered.\n",
    "\n",
    "‚ÄúIndeed, I should have thought a little more. Just a triffle more,\n",
    "\n",
    "I fancy, Watson. And in practice again, I observe. You did not\n",
    "\n",
    "tell me that your intended to go into harness.‚Äù\n",
    "\n",
    "‚ÄúThen, how do you now?‚Äù\n",
    "\n",
    "‚ÄúI see it, I deduce it. How do I know that you have been getting\n",
    "\n",
    "yourself very wet lately, and that you have a most clumsy and\n",
    "\n",
    "careless servent girl?‚Äù\n",
    "\n",
    "‚ÄúMy dear Holmes,‚Äù said I, ‚Äúthis is to much. You would certainly\n",
    "\n",
    "have been burned, had you lived a few centuries ago. It is true\n",
    "\n",
    "that I had a country walk on Thursday and came home in a dreadful\n",
    "\n",
    "mess, but as I have changed my cloths I can‚Äôt imagine how you\n",
    "\n",
    "deduce it. As to Mary Jane, she is incorrigable, and my wife has\n",
    "\n",
    "given her notice, but their, again, I fail to see how you work it\n",
    "\n",
    "out.‚Äù\n",
    "\n",
    "He chuckled to himself and rubbed his long, nervous hands\n",
    "\n",
    "together.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"His manner was not effusive. It seldom was; but he was glad, I\n",
       "\n",
       "think, to see me. With hardly a word spoken, but with a kindly\n",
       "\n",
       "eye, he waved me to an armchair, threw across his case of cigars,\n",
       "\n",
       "and indicated a spirit case and a gasogene in the corner. When he\n",
       "\n",
       "stood before the fire and looked me over in his singular\n",
       "\n",
       "introspective fashion.\n",
       "\n",
       "‚ÄúWedlock suits you,‚Äù he remarked. ‚ÄúI think, Watson, that you have\n",
       "\n",
       "put on seven and a half pounds since I saw you.‚Äù\n",
       "\n",
       "‚ÄúEven!‚Äù I answered.\n",
       "\n",
       "‚ÄúIndeed, I should have thought a little more. Must a trifle more,\n",
       "\n",
       "I fancy, Watson. And in practice again, I observe. You did not\n",
       "\n",
       "tell me that your intended to go into harness.‚Äù\n",
       "\n",
       "‚ÄúWhen, how do you now?‚Äù\n",
       "\n",
       "‚ÄúI see it, I deduce it. Now do I know that you have been getting\n",
       "\n",
       "yourself very wet lately, and that you have a most clumsy and\n",
       "\n",
       "careless servant girl?‚Äù\n",
       "\n",
       "‚ÄúBy dear Holmes,‚Äù said I, ‚Äúthis is to much. You would certainly\n",
       "\n",
       "have been burned, had you lived a few centuries ago. It is true\n",
       "\n",
       "that I had a country walk on Thursday and came home in a dreadful\n",
       "\n",
       "mess, but as I have changed my cloths I can‚Äôt imagine how you\n",
       "\n",
       "deduce it. Is to Mary Lane, she is incorrigible, and my wife has\n",
       "\n",
       "given her notice, but their, again, I fail to see how you work it\n",
       "\n",
       "out.‚Äù\n",
       "\n",
       "He chuckled to himself and rubbed his long, nervous hands\n",
       "\n",
       "together.\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlb = TextBlob(incorrect_text)\n",
    "\n",
    "TextBlb.correct()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step -3 Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "dummy = \"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\panka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = sent_tokenize(dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry.',\n",
       " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.\",\n",
       " 'It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.',\n",
       " 'It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem', 'Ipsum', 'is', 'simply', 'dummy', 'text', 'of', 'the', 'printing', 'and', 'typesetting', 'industry', '.']\n",
      "['Lorem', 'Ipsum', 'has', 'been', 'the', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', 'the', '1500s', ',', 'when', 'an', 'unknown', 'printer', 'took', 'a', 'galley', 'of', 'type', 'and', 'scrambled', 'it', 'to', 'make', 'a', 'type', 'specimen', 'book', '.']\n",
      "['It', 'has', 'survived', 'not', 'only', 'five', 'centuries', ',', 'but', 'also', 'the', 'leap', 'into', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.']\n",
      "['It', 'was', 'popularised', 'in', 'the', '1960s', 'with', 'the', 'release', 'of', 'Letraset', 'sheets', 'containing', 'Lorem', 'Ipsum', 'passages', ',', 'and', 'more', 'recently', 'with', 'desktop', 'publishing', 'software', 'like', 'Aldus', 'PageMaker', 'including', 'versions', 'of', 'Lorem', 'Ipsum']\n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    print(word_tokenize(sent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
